{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e077be2",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- https://www.youtube.com/watch?v=aLOQD66Sj0g\n",
    "- https://www.youtube.com/watch?v=33fGfuleXw0\n",
    "- https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF (search XGBoost pat 1-4 + overall video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b25e8c",
   "metadata": {},
   "source": [
    "An optimized implementation of Gradient Boosting is also available in the library $XGBoost$. Also early stoping is already implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, train_size = 0.2, random_state=42)\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
